# Docker-Essential-Linkedin

https://www.linkedin.com/learning/docker-essential-training/docker-recap?resume=false

Docker recap
Selecting transcript lines in this section will navigate to timestamp in the video
- [Instructor] Let's start off with a brief overview of what Docker is and how it works.
![image](https://github.com/swamychikatla/Docker-Essential-Linkedin/assets/40513374/bd6b4ab3-0ec6-460e-9ec3-97a8d8a21849)
Getting code working properly across multiple machines can be challenging for multiple reasons. Sometimes the operating system and application was written and tested in differs from the OS it will eventually land up in, or maybe your app might make assumptions on hardware files or other properties that might not be true on other machines. Or maybe your app depends on hardware that's on your machine, but not others. Several tools were born to solve this hairy problem.

![image](https://github.com/swamychikatla/Docker-Essential-Linkedin/assets/40513374/b357558c-e705-4956-80c8-9faeea214e39)

Configuration management tools like Chef, Ansible, and Puppet addressed it by using configuration as code to allow admins and developers to bring groups of machines to a desired state. Unfortunately, this came with its own set of challenges. You often needed to install stuff on the machines being managed by these tools before the tools could configure them. Even though these tools were based on Ruby or Python, we'll forget the one that was based on C++. You'll need to learn markup languages and frameworks, on top of whatever tech stack you will already using. 
HashiCorp solved this problem with Vagrant a tool that gives developers the ability to bring up and configure pre-made virtual machines with HCL, HashiCorp Configuration Language. That's actually what HCL stands for. Cool, right? However, virtual machines took up lots of resources and often needed additional configuration after they was started. In fact, many Vagrant users use configuration management tools to configure VMs created by Vagrant. All of this made writing code more cumbersome and time consuming.
![image](https://github.com/swamychikatla/Docker-Essential-Linkedin/assets/40513374/014b693b-6ba8-4a14-a765-1417213f9a2c)
![image](https://github.com/swamychikatla/Docker-Essential-Linkedin/assets/40513374/87ff530e-5155-41e7-833b-635f8a7ceec3)

Dockers took a different approach. Docker uses images and containers to package and run applications anywhere. Containers combine control groups and name spaces. Two Linux kernel features to create virtual operating system Instances that from the outside look like any other application on your machine. Images are snapshots of file systems that are smashed together and configured to look like a single file system to the containers that use them. Containers and images are not new. From truths, to zones, to Linux containers, these ideas have been around for a very long time. Docker makes these concepts significantly easier to use and understand in three key ways. First, containers and images are configured with the lightweight configuration file format called the Docker file. Second, images can be shared with others and retrieved by other machines to container registries. And third, its command line client uses APIs and systems black magic to make creating and operating containers a breeze. Putting this together, instead of configuring machines deploying your apps into them, and hoping for the best you use Docker files to build and configure your apps into docker images that containers will be created from. Since those images have everything your app needs to successfully run, your app will behave the same regardless of the machine that it's on. Pretty nifty stuff. Now before we move on let's talk about what docker containers are not. Many people think that containers are smaller virtual machines. They are not. Let's take a look at some key differences. Virtual machines use software called hypervisors to bridge hardware emulated in software with real hardware underneath. For all intents and purposes, they are real computers. Now, because they are real computers, they can run multiple apps at once and they can't see or interact with the hosts that they run on. We've mentioned earlier that containers use control groups and namespaces. Namespaces specify what containers can access on a Linux system and control group specify how much of a particular resource containers can consume. Containers work with container run times to configure these properties. Containers do not emulate hardware. They use the same hardware as any other app on your machine. As a result, containers can potentially interact with your hosts, but the good news is that you can control how containers interact with their hosts and we'll learn more about that later in this course. Finally, containers are designed to only run a single app at a time. There are ways around this though and we'll learn about that later too.

Give feedback
